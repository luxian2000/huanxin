#!/usr/bin/env python3
"""
QAE083æ•°æ®é›†åˆ†æè„šæœ¬

åˆ†æQAE083.pyä¸­ä½¿ç”¨çš„CSIæ•°æ®é›†çš„è¯¦ç»†å½¢çŠ¶ä¿¡æ¯ï¼Œ
åŒ…æ‹¬åŸå§‹æ•°æ®ã€è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†ç­‰ã€‚
"""

import os
import numpy as np
import sys

def analyze_qae083_dataset():
    """åˆ†æQAE083.pyä½¿ç”¨çš„æ•°æ®é›†"""
    
    print("=" * 60)
    print("QAE083 æ•°æ®é›†å½¢çŠ¶åˆ†æ")
    print("=" * 60)
    
    # QAE083.pyä¸­å®šä¹‰çš„æ•°æ®è·¯å¾„
    data_paths = [
        "/Users/luxian/DataSpace/csi_cmri/CSI_channel_30km.npy",
        "./CSI_channel_30km.npy",
        "../DataSpace/csi_cmri/CSI_channel_30km.npy",
        "../../DataSpace/csi_cmri/CSI_channel_30km.npy",
    ]
    
    data_file = None
    for path in data_paths:
        if os.path.exists(path):
            data_file = path
            break
    
    if data_file is None:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼")
        print("è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€å­˜åœ¨æ•°æ®æ–‡ä»¶ï¼š")
        for path in data_paths:
            print(f"  - {path}")
        return False
    
    print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_file}")
    
    try:
        # åŠ è½½æ•°æ®
        print("\næ­£åœ¨åŠ è½½æ•°æ®...")
        data_30 = np.load(data_file)
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
        
        # åŸºæœ¬å½¢çŠ¶ä¿¡æ¯
        print(f"\nğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶åˆ†æ:")
        print(f"   æ•°æ®å½¢çŠ¶: {data_30.shape}")
        print(f"   æ•°æ®ç±»å‹: {data_30.dtype}")
        print(f"   æ•°æ®å¤§å°: {data_30.size:,} ä¸ªå…ƒç´ ")
        print(f"   å†…å­˜å ç”¨: {data_30.nbytes / (1024**2):.2f} MB")
        
        # æ•°å€¼èŒƒå›´å’Œç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æœ€å°å€¼: {data_30.min():.6f}")
        print(f"   æœ€å¤§å€¼: {data_30.max():.6f}")
        print(f"   å¹³å‡å€¼: {data_30.mean():.6f}")
        print(f"   æ ‡å‡†å·®: {data_30.std():.6f}")
        
        # QAE083.pyä¸­çš„æ•°æ®åˆ’åˆ†å‚æ•°
        print(f"\nğŸ“‹ QAE083.py æ•°æ®åˆ’åˆ†å‚æ•°:")
        TOTAL_SAMPLES = data_30.shape[0]
        TRAIN_RATIO = 0.70
        VAL_RATIO = 0.15
        TEST_RATIO = 0.15
        
        train_size = int(TOTAL_SAMPLES * TRAIN_RATIO)
        val_size = int(TOTAL_SAMPLES * VAL_RATIO)
        test_size = TOTAL_SAMPLES - train_size - val_size
        
        print(f"   æ€»æ ·æœ¬æ•°: {TOTAL_SAMPLES:,}")
        print(f"   è®­ç»ƒé›†æ¯”ä¾‹: {TRAIN_RATIO*100:.1f}% â†’ {train_size:,} ä¸ªæ ·æœ¬")
        print(f"   éªŒè¯é›†æ¯”ä¾‹: {VAL_RATIO*100:.1f}% â†’ {val_size:,} ä¸ªæ ·æœ¬")
        print(f"   æµ‹è¯•é›†æ¯”ä¾‹: {TEST_RATIO*100:.1f}% â†’ {test_size:,} ä¸ªæ ·æœ¬")
        
        # å®é™…æ•°æ®åˆ’åˆ†
        print(f"\nğŸ” å®é™…æ•°æ®åˆ’åˆ†:")
        train_data = data_30[:train_size]
        val_data = data_30[train_size:train_size + val_size]
        test_data = data_30[train_size + val_size:]
        
        print(f"   è®­ç»ƒé›†å½¢çŠ¶: {train_data.shape}")
        print(f"   éªŒè¯é›†å½¢çŠ¶: {val_data.shape}")
        print(f"   æµ‹è¯•é›†å½¢çŠ¶: {test_data.shape}")
        
        # æ£€æŸ¥æ•°æ®ç»´åº¦
        input_dim = data_30.shape[1] if len(data_30.shape) > 1 else data_30.shape[0]
        print(f"\nğŸ“ è¾“å…¥ç»´åº¦åˆ†æ:")
        print(f"   è¾“å…¥ç»´åº¦: {input_dim}")
        print(f"   æ˜¯å¦ç¬¦åˆQAE083è¦æ±‚ (2560ç»´): {'âœ… æ˜¯' if input_dim == 2560 else 'âŒ å¦'}")
        
        if input_dim != 2560:
            print(f"   âš ï¸  æ³¨æ„: QAE083.pyæœŸæœ›2560ç»´è¾“å…¥ï¼Œä½†å½“å‰æ•°æ®ä¸º{input_dim}ç»´")
        
        # ç½‘ç»œå‚æ•°ç›¸å…³
        ENCODED_DIM = 256
        N_LAYERS = 4
        DATA_QUBITS = int(np.ceil(np.log2(ENCODED_DIM)))
        
        print(f"\nâš™ï¸  QAE083ç½‘ç»œå‚æ•°:")
        print(f"   ç¼–ç ç»´åº¦: {ENCODED_DIM}")
        print(f"   é‡å­æ¯”ç‰¹æ•°: {DATA_QUBITS}")
        print(f"   é‡å­å±‚æ•°: {N_LAYERS}")
        print(f"   é‡å­å‚æ•°æ•°é‡: {DATA_QUBITS * N_LAYERS * 3}")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        nan_count = np.isnan(data_30).sum()
        inf_count = np.isinf(data_30).sum()
        
        print(f"   NaNå€¼æ•°é‡: {nan_count}")
        print(f"   æ— ç©·å€¼æ•°é‡: {inf_count}")
        print(f"   æ•°æ®å®Œæ•´æ€§: {'âœ… è‰¯å¥½' if (nan_count == 0 and inf_count == 0) else 'âŒ å­˜åœ¨é—®é¢˜'}")
        
        # æ ·æœ¬ç¤ºä¾‹
        print(f"\nğŸ“ æ ·æœ¬ç¤ºä¾‹ (å‰3ä¸ªæ ·æœ¬çš„å‰10ä¸ªç‰¹å¾):")
        for i in range(min(3, len(data_30))):
            sample = data_30[i][:10] if len(data_30.shape) > 1 else data_30[:10]
            print(f"   æ ·æœ¬ {i+1}: {sample}")
        
        print(f"\n" + "=" * 60)
        print("âœ… æ•°æ®é›†åˆ†æå®Œæˆï¼")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_with_csinet():
    """ä¸CsiNetçš„æ•°æ®æ ¼å¼è¿›è¡Œæ¯”è¾ƒ"""
    print(f"\nğŸ”„ ä¸CsiNetæ•°æ®æ ¼å¼æ¯”è¾ƒ:")
    print(f"   QAE083: ç›´æ¥å¤„ç† {2560} ç»´å‘é‡")
    print(f"   CsiNet: å°† {2048} ç»´æ•°æ®reshapeä¸º (2, 32, 32) å›¾åƒæ ¼å¼")
    print(f"   å·®å¼‚: QAE083ä½¿ç”¨æ›´é«˜ç»´åº¦çš„æ•°æ® ({2560} vs {2048})")

if __name__ == "__main__":
    success = analyze_qae083_dataset()
    if success:
        compare_with_csinet()
    else:
        sys.exit(1)